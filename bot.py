#!/usr/bin/env python3
# bot.py - –ù–æ–≤–æ—Å—Ç–Ω–æ–π –±–æ—Ç –¥–ª—è –∫–∞–Ω–∞–ª–∞ "Live –ü–∏—Ç–µ—Ä üì∏" (–∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è)
import os
import time
import json
import random
import asyncio
import aiohttp
import re
import signal
import sys
from datetime import datetime
from bs4 import BeautifulSoup
from telebot.async_telebot import AsyncTeleBot
from dotenv import load_dotenv

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–ø–æ–∫
os.makedirs('./static', exist_ok=True)
print(f"üìÅ –ü–∞–ø–∫–∞ static —Å–æ–∑–¥–∞–Ω–∞/–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
BOT_TOKEN = os.getenv("BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID", "@LivePiter")
AUTO_POST_INTERVAL = int(os.getenv("AUTO_POST_INTERVAL", "1800"))
PORT = int(os.getenv("PORT", "10000"))
RENDER_APP_URL = os.getenv("RENDER_APP_URL", "")

if not BOT_TOKEN:
    raise SystemExit("‚ùå BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = AsyncTeleBot(BOT_TOKEN)

# --- –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∑–∞–≥–ª—É—à–∫–∏ ---
DEFAULT_PLACEHOLDER_PATH = './static/placeholder.jpg'

# --- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ ---
def load_posted_news():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    try:
        posted_json = os.getenv("POSTED_NEWS", "[]")
        posted_set = set(json.loads(posted_json))
        
        if os.path.exists('posted.json'):
            with open('posted.json', 'r', encoding='utf-8') as f:
                file_data = json.load(f)
                posted_set.update(file_data)
                
        return posted_set
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ posted news: {e}")
        return set()

def save_posted_news(posted_news_set):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    try:
        posted_list = list(posted_news_set)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(posted_list)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        os.environ["POSTED_NEWS"] = json.dumps(posted_list)
        
        with open('posted.json', 'w', encoding='utf-8') as f:
            json.dump(posted_list, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è posted news: {e}")

posted_news = load_posted_news()

# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ ---
def signal_handler(signum, frame):
    print(f"üîª –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signum}, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ...")
    save_posted_news(posted_news)
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# --- HTTP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –∑–¥–æ—Ä–æ–≤—å—è ---
async def health_server():
    """HTTP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è"""
    from aiohttp import web
    
    async def health_check(request):
        return web.Response(
            text=json.dumps({
                "status": "üü¢ –ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç",
                "sources": len(NEWS_SOURCES),
                "posted": len(posted_news),
                "timestamp": datetime.now().isoformat(),
                "version": "5.0 –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è"
            }, ensure_ascii=False),
            content_type='application/json'
        )
    
    app = web.Application()
    app.router.add_get('/health', health_check)
    app.router.add_get('/', health_check)
    
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', PORT)
    await site.start()
    print(f"üåê HTTP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {PORT}")
    
    return runner

# --- Keep-Alive –¥–ª—è Render ---
async def enhanced_keep_alive():
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π keep-alive —Å –≤–Ω–µ—à–Ω–∏–º –ø–∏–Ω–≥–∏–Ω–≥–æ–º"""
    print("üîÑ –ó–ê–ü–£–°–ö –£–õ–£–ß–®–ï–ù–ù–û–ì–û KEEP-ALIVE...")
    
    while True:
        try:
            # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–∏–Ω–≥
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f'http://localhost:{PORT}/health', timeout=10) as resp:
                        if resp.status == 200:
                            print(f"‚úÖ –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π ping: {datetime.now().strftime('%H:%M:%S')}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ ping: {e}")
            
            # –í–Ω–µ—à–Ω–∏–π PING
            if RENDER_APP_URL:
                try:
                    async with aiohttp.ClientSession() as session:
                        random_param = f"?ping={random.randint(1000,9999)}"
                        async with session.get(f'{RENDER_APP_URL}/health{random_param}', timeout=30) as resp:
                            if resp.status == 200:
                                print(f"üåê –í–ù–ï–®–ù–ò–ô PING –£–°–ü–ï–®–ï–ù: {datetime.now().strftime('%H:%M:%S')}")
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–Ω–µ—à–Ω–µ–≥–æ ping: {e}")
            
            # –°–ª—É—á–∞–π–Ω–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è
            current_hour = datetime.now().hour
            if 8 <= current_hour <= 23:
                if random.random() < 0.3:
                    print("üé∞ –°–ª—É—á–∞–π–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è –∞–≤—Ç–æ–ø–æ—Å—Ç–∏–Ω–≥–∞...")
                    try:
                        await publish_news(1)
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ—Å—Ç–∏–Ω–≥–∞: {e}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û–±—â–∞—è –æ—à–∏–±–∫–∞ keep-alive: {e}")
        
        sleep_time = random.randint(480, 600)
        print(f"üí§ –°–ª–µ–¥—É—é—â–∏–π keep-alive —á–µ—Ä–µ–∑ {sleep_time} —Å–µ–∫—É–Ω–¥...")
        await asyncio.sleep(sleep_time)

# --- –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π ---
def extract_complete_text_from_html(html_content, title):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for element in soup(['script', 'style', 'nav', 'footer', 'aside', 'header', 'form', 'button', 'iframe']):
            element.decompose()
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_selectors = [
            'article',
            '.article',
            '.content', 
            '.news-content',
            '.post-content',
            '.text',
            '.news-text',
            '.story__content',
            '.b-article__content',
            '.js-article-content',
            '[class*="content"]',
            '[class*="article"]',
            '[class*="post"]',
            '[class*="story"]'
        ]
        
        content_element = None
        for selector in content_selectors:
            content_element = soup.select_one(selector)
            if content_element:
                break
        
        if not content_element:
            content_element = soup.find('body') or soup
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–∏–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞
        text_elements = content_element.find_all(['p', 'div', 'h2', 'h3'])
        meaningful_paragraphs = []
        
        for element in text_elements:
            text = element.get_text().strip()
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            if (len(text) > 40 and 
                not any(x in text for x in [
                    '¬©', '–§–æ—Ç–æ:', '–ò—Å—Ç–æ—á–Ω–∏–∫:', '–ß–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–∂–µ:', '–†–µ–¥–∞–∫—Ü–∏—è',
                    '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏', '–ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å', 'Rambler', '–¢–ê–°–°', 
                    'Lenta.ru', '–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏', '–ü–æ–¥–µ–ª–∏—Ç—å—Å—è', '–°–ª–µ–¥–∏—Ç–µ –∑–∞',
                    'INTERFAX.RU', 'https://', 'http://', 'www.'
                ]) and
                len(text.split()) > 8 and
                not text.startswith('http')):
                meaningful_paragraphs.append(text)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 2-3 –ø–µ—Ä–≤—ã—Ö –∑–Ω–∞—á–∏–º—ã—Ö –∞–±–∑–∞—Ü–∞
        if meaningful_paragraphs:
            selected_paragraphs = meaningful_paragraphs[:3]  # –¢–æ–ª—å–∫–æ 2-3 –∞–±–∑–∞—Ü–∞
            full_text = '\n\n'.join(selected_paragraphs)
            
            if len(full_text.split()) < 50:
                full_text = f"{title}\n\n{full_text}"
            
            return full_text[:3000]  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ª–∏–º–∏—Ç
            
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}")
    
    return ""

def remove_duplicate_text(text):
    """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–æ–≤–æ—Å—Ç–∏"""
    if not text:
        return text
    
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    unique_sentences = []
    seen_sentences = set()
    
    for sentence in sentences:
        normalized = re.sub(r'\s+', ' ', sentence).strip().lower()
        if normalized and normalized not in seen_sentences:
            seen_sentences.add(normalized)
            unique_sentences.append(sentence)
    
    cleaned_text = '. '.join(unique_sentences) + '.' if unique_sentences else ''
    
    if len(cleaned_text.split()) < 20 and len(text.split()) > 30:
        return text
    
    return cleaned_text

def create_engaging_title(original_title):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–ª—è—é—â–µ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    clean_title = original_title
    
    # –£–±–∏—Ä–∞–µ–º URL –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    clean_title = re.sub(r'https?://\S+|www\.\S+', '', clean_title)
    clean_title = re.sub(r'\b(INTERFAX\.RU|–†–ò–ê\s*–ù–æ–≤–æ—Å—Ç–∏|–¢–ê–°–°|Lenta\.ru|Rambler)\b', '', clean_title, flags=re.IGNORECASE)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ç–∏—Ä–µ –∏ —Ç–æ—á–∫–∏
    clean_title = re.sub(r'[‚Äì‚Äî]\s*[‚Äì‚Äî]+', '‚Äî', clean_title)
    clean_title = re.sub(r'\.\s*\.+', '.', clean_title)
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    clean_title = remove_duplicate_text(clean_title)
    
    # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
    if len(clean_title) > 120:
        sentences = clean_title.split('. ')
        if len(sentences) > 1:
            clean_title = sentences[0] + '.'
        else:
            clean_title = clean_title[:117] + '...'
    
    return clean_title.strip()

def format_news_live_piter_style(title, description, full_text):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ —Å—Ç–∏–ª–µ Live –ü–∏—Ç–µ—Ä üì∏ (–∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
    # –°–æ–∑–¥–∞–µ–º —á–∏—Å—Ç—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    clean_title = create_engaging_title(title)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 2-3 –∞–±–∑–∞—Ü–∞
    if full_text and len(full_text.split()) > 40:
        paragraphs = full_text.split('\n\n')
        
        # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 3 –∞–±–∑–∞—Ü–∞
        if len(paragraphs) >= 2:
            intro = paragraphs[0]
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 1-2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–±–∑–∞—Ü–∞
            additional_paragraphs = paragraphs[1:3]  # –¢–æ–ª—å–∫–æ 2-–π –∏ 3-–π –∞–±–∑–∞—Ü
            formatted_text = f"{intro}\n\n" + "\n\n".join(additional_paragraphs)
        else:
            formatted_text = full_text
    elif description and len(description.split()) > 20:
        formatted_text = description
    else:
        formatted_text = full_text if full_text else description
    
    # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    formatted_text = re.sub(r'https?://\S+|www\.\S+', '', formatted_text)
    formatted_text = re.sub(r'\b(INTERFAX\.RU|–†–ò–ê\s*–ù–æ–≤–æ—Å—Ç–∏|–¢–ê–°–°|Lenta\.ru|Rambler|–§–æ–Ω—Ç–∞–Ω–∫–∞\.—Ä—É|78\.—Ä—É|–ö–∞–Ω–Ω–∞–ª7|–ü–µ—Ç–µ—Ä–±—É—Ä–≥2|–î–ü)\b', '', formatted_text, flags=re.IGNORECASE)
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    formatted_text = remove_duplicate_text(formatted_text)
    
    # –û—á–∏—Å—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    formatted_text = re.sub(r'\s+', ' ', formatted_text)
    formatted_text = re.sub(r'\.\s+', '.\n\n', formatted_text)
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    final_text = f"{clean_title}\n\n{formatted_text}"
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    final_text = re.sub(r'\n\s*\n', '\n\n', final_text)
    
    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–æ–≤
    if len(final_text) > 3000:
        # –ò—â–µ–º –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –æ–±—Ä–µ–∑–∫–∏
        cut_position = final_text.rfind('. ', 2500, 3000)
        if cut_position == -1:
            cut_position = final_text.rfind('! ', 2500, 3000)
        if cut_position == -1:
            cut_position = final_text.rfind('? ', 2500, 3000)
        if cut_position == -1:
            cut_position = 2997
        
        final_text = final_text[:cut_position + 1]
    
    return final_text.strip()

# --- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π ---
NEWS_SOURCES = [
    # –û–±—â–µ—Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    "https://lenta.ru/rss/news",
    "https://tass.ru/rss/v2.xml", 
    "https://news.rambler.ru/rss/world/",
    
    # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    "https://www.fontanka.ru/fontanka.rss",
    "https://78.ru/text/rss.xml",
    "https://kanal7.ru/rss/",
    "https://peterburg2.ru/rss/",
    "https://www.dp.ru/rss/",
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    "https://ria.ru/export/rss2/archive/index.xml",
    "https://www.interfax.ru/rss.asp",
    "https://www.kommersant.ru/RSS/news.xml",
]

# --- –§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ ---
def extract_image_from_item(item_soup):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ RSS —ç–ª–µ–º–µ–Ω—Ç–∞"""
    image_sources = [
        lambda: item_soup.find("enclosure"),
        lambda: item_soup.find("media:content"),
        lambda: item_soup.find("media:thumbnail"),
        lambda: item_soup.find("image")
    ]
    
    for source in image_sources:
        try:
            element = source()
            if element and element.get("url"):
                url = element.get("url")
                if url and (url.startswith(('http', '//')) and 
                           any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp'])):
                    return url
        except Exception:
            continue
    return None

def find_og_image(html_content):
    """–ü–æ–∏—Å–∫ Open Graph –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ HTML"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        og_image = soup.find('meta', property='og:image')
        if og_image and og_image.get('content'):
            url = og_image.get('content')
            if url and any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                return url
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ OG –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
    return None

async def download_image(session, url):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    if not url:
        return None
        
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        if not url.startswith('http'):
            if url.startswith('//'):
                url = 'https:' + url
            else:
                return None
        
        async with session.get(url, headers=headers, timeout=30) as response:
            if response.status == 200:
                content_type = response.headers.get('content-type', '')
                if 'image' in content_type:
                    filename = f"./temp_image_{int(time.time())}_{random.randint(1000, 9999)}.jpg"
                    content = await response.read()
                    
                    if len(content) > 10240:
                        with open(filename, 'wb') as f:
                            f.write(content)
                        return filename
                
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {url}: {e}")
    
    return None

async def get_news_from_source(session, source_url, limit=5):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        
        print(f"üîç –ó–∞–ø—Ä–æ—Å –∫: {source_url}")
        async with session.get(source_url, headers=headers, timeout=15) as response:
            if response.status != 200:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {response.status} –¥–ª—è {source_url}")
                return []
                
            content = await response.text()
            soup = BeautifulSoup(content, 'xml')
            items = soup.find_all('item')[:limit]
            
            news_items = []
            for item in items:
                try:
                    title_elem = item.find('title')
                    link_elem = item.find('link')
                    description_elem = item.find('description')
                    
                    if not title_elem or not link_elem:
                        continue
                        
                    title = title_elem.get_text().strip()
                    link = link_elem.get_text().strip()
                    description = ""
                    
                    if description_elem:
                        description = re.sub(r'<[^>]+>', '', description_elem.get_text()).strip()
                    
                    if not title or not link:
                        continue
                    
                    image_url = extract_image_from_item(item)
                    
                    # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ—Ç –≤ RSS, –∏—â–µ–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    if not image_url and link:
                        try:
                            async with session.get(link, headers=headers, timeout=8) as page_response:
                                if page_response.status == 200:
                                    page_content = await page_response.text()
                                    image_url = find_og_image(page_content)
                        except Exception as e:
                            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {e}")
                    
                    news_items.append({
                        'title': title,
                        'link': link,
                        'description': description,
                        'source': source_url,
                        'image': image_url
                    })
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ {source_url}: {e}")
                    continue
            
            print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {source_url}")
            return news_items
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {source_url}: {e}")
        return []

async def get_all_news(limit_per_source=5):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    print("üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
    
    async with aiohttp.ClientSession() as session:
        tasks = []
        for source in NEWS_SOURCES:
            task = get_news_from_source(session, source, limit_per_source)
            tasks.append(task)
            await asyncio.sleep(1)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_news = []
        for result in results:
            if isinstance(result, list):
                all_news.extend(result)
        
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(all_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {len(NEWS_SOURCES)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        return all_news

async def get_extended_news_text(link, title, session):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    if not link:
        return ""
        
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        async with session.get(link, headers=headers, timeout=10) as response:
            if response.status == 200:
                html = await response.text()
                return extract_complete_text_from_html(html, title)
                    
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
    
    return ""

async def prepare_news_item(item):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏ –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
    title = item.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')
    link = item.get('link', '')
    description = item.get('description', '')
    image_url = item.get('image', '')
    
    print(f"üìù –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞: {title[:60]}...")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏
    news_text = ""
    if link:
        async with aiohttp.ClientSession() as session:
            news_text = await get_extended_news_text(link, title, session)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ —Å—Ç–∏–ª–µ Live –ü–∏—Ç–µ—Ä
    final_text = format_news_live_piter_style(title, description, news_text)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
    word_count = len(final_text.split())
    if word_count < 40:
        print(f"‚ùå –ü—Ä–æ–ø—É—â–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å: '{title[:30]}...' - –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞ ({word_count} —Å–ª–æ–≤)")
        return None
    
    print(f"‚úÖ –¢–µ–∫—Å—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω: {word_count} —Å–ª–æ–≤")
    
    # –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    image_path = None
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –Ω–æ–≤–æ—Å—Ç–∏
    if image_url:
        async with aiohttp.ClientSession() as session:
            image_path = await download_image(session, image_url)
            if image_path:
                print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –Ω–æ–≤–æ—Å—Ç–∏")
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É –∏–∑ static
    if not image_path:
        if os.path.exists(DEFAULT_PLACEHOLDER_PATH):
            image_path = DEFAULT_PLACEHOLDER_PATH
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É –∏–∑ –ø–∞–ø–∫–∏ static")
        else:
            print("‚ö†Ô∏è –ó–∞–≥–ª—É—à–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ static, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    return {
        'title': title,
        'summary': final_text,
        'link': link,
        'image_path': image_path,
        'word_count': word_count
    }

async def send_news_to_channel(news_item):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∫–∞–Ω–∞–ª"""
    try:
        title = news_item['title']
        summary = news_item['summary']
        image_path = news_item['image_path']
        word_count = news_item['word_count']
        
        print(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏: {title[:50]}...")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        message_text = summary
        
        if image_path and os.path.exists(image_path):
            print(f"üñºÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
            try:
                with open(image_path, 'rb') as photo:
                    await bot.send_photo(
                        CHANNEL_ID,
                        photo,
                        caption=message_text,
                        parse_mode='HTML'
                    )
                print("‚úÖ –ù–æ–≤–æ—Å—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞")
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–∫—Ä–æ–º–µ –∑–∞–≥–ª—É—à–∫–∏ –∏–∑ static)
                if 'temp_image_' in image_path:
                    try:
                        os.remove(image_path)
                        print("‚úÖ –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω")
                    except Exception as e:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {e}")
                        
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {e}")
                # Fallback: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                await bot.send_message(
                    CHANNEL_ID,
                    message_text,
                    parse_mode='HTML'
                )
        else:
            print("‚ÑπÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç")
            await bot.send_message(
                CHANNEL_ID,
                message_text,
                parse_mode='HTML'
            )
        
        print(f"‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {title[:70]}... ({word_count} —Å–ª–æ–≤)")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
        return False

async def publish_news(count=1):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ {count} –Ω–æ–≤–æ—Å—Ç–µ–π...")
    
    all_news = await get_all_news()
    if not all_news:
        print("‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return 0
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
    new_news = []
    for item in all_news:
        news_id = item.get('link') or item.get('title')
        if news_id and news_id not in posted_news:
            new_news.append(item)
    
    if not new_news:
        print("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
        return 0
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
    random.shuffle(new_news)
    
    published_count = 0
    attempts = 0
    max_attempts = min(len(new_news) * 2, 15)
    
    while published_count < count and attempts < max_attempts:
        if attempts >= len(new_news):
            break
            
        item = new_news[attempts]
        attempts += 1
        
        try:
            prepared_item = await prepare_news_item(item)
            
            if prepared_item is None:
                continue
                
            success = await send_news_to_channel(prepared_item)
            
            if success:
                news_id = item.get('link') or item.get('title')
                if news_id:
                    posted_news.add(news_id)
                    published_count += 1
                    save_posted_news(posted_news)
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º–∏
                await asyncio.sleep(random.randint(45, 120))
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
            continue
    
    print(f"‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {published_count} –∏–∑ {count} –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö")
    return published_count

# --- –ö–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞ ---
@bot.message_handler(commands=['start'])
async def send_welcome(message):
    welcome_text = """
ü§ñ –ù–æ–≤–æ—Å—Ç–Ω–æ–π –±–æ—Ç –¥–ª—è –∫–∞–Ω–∞–ª–∞ "Live –ü–∏—Ç–µ—Ä üì∏"
–ö–û–ú–ü–ê–ö–¢–ù–ê–Ø –í–ï–†–°–ò–Ø

üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫–∏:
‚Ä¢ 3 —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –ø–æ—Ä—Ç–∞–ª–∞
‚Ä¢ 5 –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∏—Ç–µ—Ä—Å–∫–∏—Ö –∏–∑–¥–∞–Ω–∏–π
‚Ä¢ 3 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –Ω–∞–¥–µ–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞

üéØ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
‚Ä¢ –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (2-3 –∞–±–∑–∞—Ü–∞)
‚Ä¢ –ó–∞–≥–ª—É—à–∫–∞ –∏–∑ –ø–∞–ø–∫–∏ static
‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω—ã–π keep-alive
‚Ä¢ –ê–≤—Ç–æ–ø–æ—Å—Ç–∏–Ω–≥ –≤ —Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è

üìã –ö–æ–º–∞–Ω–¥—ã:
/post - –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏
/status - –°—Ç–∞—Ç—É—Å –±–æ—Ç–∞  
/stats - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
/sources - –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
/wake - –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è
"""
    await bot.reply_to(message, welcome_text)

@bot.message_handler(commands=['wake'])
async def force_wake(message):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è –±–æ—Ç–∞"""
    try:
        await bot.reply_to(message, "üîî –ê–∫—Ç–∏–≤–∏—Ä—É—é –±–æ—Ç–∞...")
        await publish_news(1)
        await bot.reply_to(message, "‚úÖ –ë–æ—Ç –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –∏ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª –Ω–æ–≤–æ—Å—Ç—å")
    except Exception as e:
        await bot.reply_to(message, f"‚ùå –û—à–∏–±–∫–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {e}")

@bot.message_handler(commands=['post'])
async def manual_post(message):
    try:
        await bot.reply_to(message, "‚è≥ –ó–∞–ø—É—Å–∫–∞—é –ø—É–±–ª–∏–∫–∞—Ü–∏—é –Ω–æ–≤–æ—Å—Ç–µ–π...")
        count = random.randint(1, 2)
        published = await publish_news(count)
        await bot.reply_to(message, f"‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ {published} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Å—Ç–∏–ª–µ 'Live –ü–∏—Ç–µ—Ä üì∏'")
    except Exception as e:
        await bot.reply_to(message, f"‚ùå –û—à–∏–±–∫–∞: {e}")

@bot.message_handler(commands=['status'])
async def bot_status(message):
    status_text = f"""
üìä –°—Ç–∞—Ç—É—Å –±–æ—Ç–∞ (–ö–û–ú–ü–ê–ö–¢–ù–ê–Ø –í–ï–†–°–ò–Ø):

ü§ñ –ë–æ—Ç: –ê–∫—Ç–∏–≤–µ–Ω
üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(NEWS_SOURCES)}
üì® –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {len(posted_news)}
üéØ –§–æ—Ä–º–∞—Ç: –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (2-3 –∞–±–∑–∞—Ü–∞)
‚è∞ Keep-alive: –∫–∞–∂–¥—ã–µ 8-10 –º–∏–Ω—É—Ç
üåê –í–Ω–µ—à–Ω–∏–π ping: {'‚úÖ –í–∫–ª—é—á–µ–Ω' if RENDER_APP_URL else '‚ùå –í—ã–∫–ª—é—á–µ–Ω'}
üñºÔ∏è –ó–∞–≥–ª—É—à–∫–∞: {'‚úÖ –í –ø–∞–ø–∫–µ static' if os.path.exists(DEFAULT_PLACEHOLDER_PATH) else '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞'}
"""
    await bot.reply_to(message, status_text)

@bot.message_handler(commands=['stats'])
async def bot_stats(message):
    stats_text = f"""
üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:

üìä –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(posted_news)}
üîó –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ({len(NEWS_SOURCES)}):
"""
    for source in NEWS_SOURCES:
        source_name = source.split('//')[-1].split('/')[0]
        stats_text += f"   ‚Ä¢ {source_name}\n"
    
    await bot.reply_to(message, stats_text)

@bot.message_handler(commands=['sources'])
async def show_sources(message):
    sources_text = "üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π:\n\n"
    
    federal = [s for s in NEWS_SOURCES if 'lenta' in s or 'tass' in s or 'rambler' in s or 'ria' in s or 'interfax' in s or 'kommersant' in s]
    local = [s for s in NEWS_SOURCES if s not in federal]
    
    sources_text += "üèõÔ∏è –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ:\n"
    for source in federal:
        source_name = source.split('//')[-1].split('/')[0]
        sources_text += f"‚Ä¢ {source_name}\n"
    
    sources_text += "\nüèôÔ∏è –ü–∏—Ç–µ—Ä—Å–∫–∏–µ:\n"
    for source in local:
        source_name = source.split('//')[-1].split('/')[0]
        sources_text += f"‚Ä¢ {source_name}\n"
    
    await bot.reply_to(message, sources_text)

async def auto_poster():
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
    print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏...")
    
    while True:
        try:
            # –ü—É–±–ª–∏–∫—É–µ–º –≤ –∞–∫—Ç–∏–≤–Ω–æ–µ –≤—Ä–µ–º—è (8:00-23:00)
            current_hour = datetime.now().hour
            if 8 <= current_hour <= 23:
                news_count = random.randint(1, 2)
                print(f"üì∞ –ê–≤—Ç–æ–ø–æ—Å—Ç–∏–Ω–≥: –ø—É–±–ª–∏–∫—É—é {news_count} –Ω–æ–≤–æ—Å—Ç–µ–π...")
                await publish_news(news_count)
            else:
                print("üí§ –ù–æ—á–Ω–æ–µ –≤—Ä–µ–º—è, –∞–≤—Ç–æ–ø–æ—Å—Ç–∏–Ω–≥ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
            # –°–ª—É—á–∞–π–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª 25-40 –º–∏–Ω—É—Ç
            sleep_time = random.randint(1500, 2400)
            print(f"‚è≥ –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ {sleep_time//60} –º–∏–Ω—É—Ç...")
            await asyncio.sleep(sleep_time)
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –∞–≤—Ç–æ-–ø–æ—Å—Ç–∏–Ω–≥–µ: {e}")
            await asyncio.sleep(600)

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –±–æ—Ç–∞ 'Live –ü–∏—Ç–µ—Ä üì∏' (–ö–û–ú–ü–ê–ö–¢–ù–ê–Ø –í–ï–†–°–ò–Ø)...")
    print(f"üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(NEWS_SOURCES)}")
    print(f"üéØ –§–æ—Ä–º–∞—Ç: –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (2-3 –∞–±–∑–∞—Ü–∞)")
    print(f"‚è∞ Keep-alive: –∫–∞–∂–¥—ã–µ 8-10 –º–∏–Ω—É—Ç")
    print(f"üåê –í–Ω–µ—à–Ω–∏–π URL: {RENDER_APP_URL or '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}")
    print(f"üì∫ –ö–∞–Ω–∞–ª: {CHANNEL_ID}")
    print(f"üñºÔ∏è –ó–∞–≥–ª—É—à–∫–∞: {DEFAULT_PLACEHOLDER_PATH}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞–≥–ª—É—à–∫–∏
    if not os.path.exists(DEFAULT_PLACEHOLDER_PATH):
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–≥–ª—É—à–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ø–∞–ø–∫–µ static!")
        print("‚ÑπÔ∏è –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ä–µ–∂–∏–º –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º HTTP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –∑–¥–æ—Ä–æ–≤—å—è
    health_runner = await health_server()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –í–°–ï –∑–∞–¥–∞—á–∏
        tasks = [
            asyncio.create_task(bot.polling(non_stop=True)),
            asyncio.create_task(auto_poster()),
            asyncio.create_task(enhanced_keep_alive())
        ]
        
        print("‚úÖ –í—Å–µ –∑–∞–¥–∞—á–∏ –∑–∞–ø—É—â–µ–Ω—ã")
        await asyncio.gather(*tasks)
        
    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞: {e}")
    finally:
        await health_runner.cleanup()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("üëã –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        save_posted_news(posted_news)
    except Exception as e:
        print(f"üí• –§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        save_posted_news(posted_news)


